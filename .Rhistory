summarize(Total_NB_VALD = sum(Total_NB_VALD))
library(ggplot2)
monthly_data %>%
mutate(YearMonth = as.Date(paste0(YearMonth, "-01"))) %>%  # Convert YearMonth to Date format
ggplot(aes(x = YearMonth, y = Total_NB_VALD)) +
geom_line() +  # Line plot
labs(title = "Total_NB_VALD per Month", x = "Month", y = "Total_NB_VALD") +
scale_x_date(date_labels = "%b %Y", date_breaks = "3 months") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(ggplot2)
monthly_data %>%
mutate(YearMonth = as.Date(paste0(YearMonth, "-01"))) %>%  # Convert YearMonth to Date format
ggplot(aes(x = YearMonth, y = Total_NB_VALD)) +
geom_bar(stat = "identity", fill = "skyblue") +  # Bar plot
labs(title = "Total_NB_VALD per Month", x = "Month", y = "Total_NB_VALD") +
theme_minimal() +
scale_x_date(date_labels = "%b %Y", date_breaks = "1 month")
# Filter data based on IDs
filtered_new_data <- filtered_data %>%
filter(ZdCId %in% result$ID_REFA_LDA)
# Convert to spatial object
final_data_sf <- st_as_sf(filtered_new_data, coords = c("ZdAXEpsg2154", "ZdAYEpsg2154"), crs = 2154)
# Plot monthly trends
ggplot(result, aes(x = format(JOUR, "%Y-%m"), y = Total_NB_VALD)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue") +
labs(title = "Monthly Average Ridership",
x = "Month",
y = "Mean NB_VALD")
# Plot monthly trends
ggplot(result, aes(x = format(JOUR, "%Y-%m"), y = Total_NB_VALD)) +
geom_bar(stat = "summary", fun = "sum", fill = "skyblue") +
labs(title = "Monthly Average Ridership",
x = "Month",
y = "Mean NB_VALD")
# Plot monthly trends
ggplot(result, aes(x = format(JOUR, "%Y-%m"), y = Total_NB_VALD)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue") +
labs(title = "Monthly Average Ridership",
x = "Month",
y = "Mean NB_VALD")
library(dplyr)
library(lubridate)
monthly_data <- result %>%
mutate(YearMonth = format(JOUR, "%Y-%m")) %>%
group_by(YearMonth) %>%
summarize(Total_NB_VALD = mean(Total_NB_VALD))
library(ggplot2)
monthly_data %>%
mutate(YearMonth = as.Date(paste0(YearMonth, "-01"))) %>%  # Convert YearMonth to Date format
ggplot(aes(x = YearMonth, y = Total_NB_VALD)) +
geom_line() +  # Line plot
labs(title = "Total_NB_VALD per Month", x = "Month", y = "Total_NB_VALD") +
scale_x_date(date_labels = "%b %Y", date_breaks = "3 months") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(ggplot2)
library(scales)  # For date formatting
# Assuming JOUR is already in Date format
ggplot(result, aes(x = JOUR, y = Total_NB_VALD)) +
geom_line() +
labs(title = "Daily Ridership Trends",
x = "Date",
y = "Total_NB_VALD") +
library(ggplot2)
library(scales)  # For date formatting
# Assuming JOUR is already in Date format
ggplot(result, aes(x = JOUR, y = Total_NB_VALD)) +
geom_line() +
labs(title = "Daily Ridership Trends",
x = "Date",
y = "Total_NB_VALD")
# Plot monthly trends
ggplot(result, aes(x = format(JOUR, "%Y-%m"), y = Total_NB_VALD)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue") +
labs(title = "Monthly Average Ridership",
x = "Month",
y = "Mean NB_VALD")+
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
install.packages("sf")
library(dplyr)
library(sf)
library(leaflet)
# Filter data based on IDs
filtered_new_data <- filtered_data %>%
filter(ZdCId %in% result$ID_REFA_LDA)
# Convert to spatial object
final_data_sf <- st_as_sf(filtered_new_data, coords = c("ZdAXEpsg2154", "ZdAYEpsg2154"), crs = 2154)
# Transform to EPSG 4326
final_data_sf <- st_transform(final_data_sf, 4326)
# Extract coordinates
filtered_new_data$X <- st_coordinates(final_data_sf)[, "X"]
filtered_new_data$Y <- st_coordinates(final_data_sf)[, "Y"]
# Create leaflet map
my_map <- leaflet() %>%
addTiles() %>%
setView(
lng = mean(st_coordinates(final_data_sf$geometry)[, "X"]),
lat = mean(st_coordinates(final_data_sf$geometry)[, "Y"]),
zoom = 11
) %>%
addMarkers(
data = filtered_new_data,
lng = ~X,  # Use the X column for longitude
lat = ~Y   # Use the Y column for latitude
)
# Show the map
my_map
library(stringi)
#result <- final_data %>%
#  filter(
#      stri_trans_tolower(ZdAName) == stri_trans_tolower(LIBELLE_ARRET)
#  )
#head(result)
result <- final_data
result
# Calculate the percentage for each value in the 'ZdAType' column
percentage_summary <- result %>%
group_by(ZdAType) %>%
summarise(Count = n()) %>%
mutate(Percentage = (Count / sum(Count)) * 100)
# Filter to show only 'railStation' and 'metroStation'
percentage_summary_filtered <- percentage_summary %>%
filter(ZdAType %in% c("railStation", "metroStation"))
# View the results
print(percentage_summary_filtered)
# Convert the date column from string to Date
result$JOUR <- as.Date(result$JOUR, format = "%d/%m/%Y")
result
library(ggplot2)
library(scales)  # For date formatting
# Assuming JOUR is already in Date format
ggplot(result, aes(x = JOUR, y = Total_NB_VALD)) +
geom_line() +
labs(title = "Daily Ridership Trends",
x = "Date",
y = "Total_NB_VALD")
# Plot monthly trends
ggplot(result, aes(x = format(JOUR, "%Y-%m"), y = Total_NB_VALD)) +
geom_bar(stat = "summary", fun = "mean", fill = "skyblue") +
labs(title = "Monthly Average Ridership",
x = "Month",
y = "Mean NB_VALD")+
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(dplyr)
library(lubridate)
monthly_data <- result %>%
mutate(YearMonth = format(JOUR, "%Y-%m")) %>%
group_by(YearMonth) %>%
summarize(Total_NB_VALD = mean(Total_NB_VALD))
library(ggplot2)
monthly_data %>%
mutate(YearMonth = as.Date(paste0(YearMonth, "-01"))) %>%  # Convert YearMonth to Date format
ggplot(aes(x = YearMonth, y = Total_NB_VALD)) +
geom_line() +  # Line plot
labs(title = "Total_NB_VALD per Month", x = "Month", y = "Total_NB_VALD") +
scale_x_date(date_labels = "%b %Y", date_breaks = "3 months") +
theme_minimal() +
theme(axis.text.x = element_text(angle = 45, hjust = 1))
library(dplyr)
library(sf)
library(leaflet)
# Filter data based on IDs
filtered_new_data <- filtered_data %>%
filter(ZdCId %in% result$ID_REFA_LDA)
# Convert to spatial object
final_data_sf <- st_as_sf(filtered_new_data, coords = c("ZdAXEpsg2154", "ZdAYEpsg2154"), crs = 2154)
# Transform to EPSG 4326
final_data_sf <- st_transform(final_data_sf, 4326)
# Extract coordinates
filtered_new_data$X <- st_coordinates(final_data_sf)[, "X"]
filtered_new_data$Y <- st_coordinates(final_data_sf)[, "Y"]
# Create leaflet map
my_map <- leaflet() %>%
addTiles() %>%
setView(
lng = mean(st_coordinates(final_data_sf$geometry)[, "X"]),
lat = mean(st_coordinates(final_data_sf$geometry)[, "Y"]),
zoom = 11
) %>%
addMarkers(
data = filtered_new_data,
lng = ~X,  # Use the X column for longitude
lat = ~Y   # Use the Y column for latitude
)
# Show the map
my_map
# Select and arrange the top 5 LIBELLE_ARRET based on NB_VALD
top_arrets <- result %>%
group_by(LIBELLE_ARRET) %>%
summarize(Total_NB_VALD = sum(Sum_NB_VALD, na.rm = TRUE)) %>%
top_n(5, Total_NB_VALD) %>%
arrange(desc(Total_NB_VALD))
# Select and arrange the top 5 LIBELLE_ARRET based on NB_VALD
top_arrets <- result %>%
group_by(LIBELLE_ARRET) %>%
summarize(Total_NB_VALD = sum(Total_NB_VALD, na.rm = TRUE)) %>%
top_n(5, Total_NB_VALD) %>%
arrange(desc(Total_NB_VALD))
# Print the result
print(top_arrets)
subset_data <- result$Total_NB_VALD[1:(3 * 60)]  #We put 60 because we have 2 lines for each day (the entries for each station). 3*60 is equivalent to 3 months.
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
result
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA)
grouped_data
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA) %>%
order_by(JOUR,ID_REFA_LDA)
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA) %>%
order_by(ID_REFA_LDA)
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA) %>%
order_by(,ID_REFA_LDA)
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA) %>%
order_by(ID_REFA_LDA)
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA) %>%
arrange(ID_REFA_LDA)
grouped_data
result
grouped_data <- result %>%
group_by(JOUR,ID_REFA_LDA)
grouped_data
subset_data <- result$Total_NB_VALD[1:(3 * 30)]  #We put 60 because we have 2 lines for each day (the entries for each station). 3*60 is equivalent to 3 months.
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(12 * 30)]  #We put 60 because we have 2 lines for each day (the entries for each station). 3*60 is equivalent to 3 months.
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(6 * 30)]  #We put 60 because we have 2 lines for each day (the entries for each station). 3*60 is equivalent to 3 months.
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(72 * 30)]  #We put 60 because we have 2 lines for each day (the entries for each station). 3*60 is equivalent to 3 months.
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(1 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(6 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
# Group by ID_REFA_LDA and LIBELLE_ARRET and count records
grouped_data <- grouped_data %>%
group_by(ID_REFA_LDA, LIBELLE_ARRET) %>%
summarize(Count = n(), .groups = 'drop') # Count the number of records
# View the grouped data
print(grouped_data)
# Optional: Filter records with more than 1 occurrence
duplicates <- grouped_data %>%
filter(Count > 1)
# View duplicates
print(duplicates)
# Load necessary library
library(dplyr)
# Count all duplicated IDs
duplicate_ids_count <- filtered_new_data %>%
group_by(ID_REFA_LDA) %>%  # Group by ID_REFA_LDA
summarize(Count = n(), .groups = 'drop') %>%  # Count the number of occurrences for each ID
filter(Count > 1) %>%  # Filter to keep only duplicated IDs
nrow()  # Count the number of rows (duplicated IDs)
# Load necessary library
library(dplyr)
# Count all duplicated IDs
duplicate_ids_count <- result %>%
group_by(ID_REFA_LDA) %>%  # Group by ID_REFA_LDA
summarize(Count = n(), .groups = 'drop') %>%  # Count the number of occurrences for each ID
filter(Count > 1) %>%  # Filter to keep only duplicated IDs
nrow()  # Count the number of rows (duplicated IDs)
# Print the total count of duplicated IDs
print(duplicate_ids_count)
# Count all duplicated IDs
duplicate_ids_count_vald <- result %>%
group_by(Total_NB_VALD) %>%  # Group by ID_REFA_LDA
summarize(Count = n(), .groups = 'drop') %>%  # Count the number of occurrences for each ID
filter(Count > 1) %>%  # Filter to keep only duplicated IDs
nrow()  # Count the number of rows (duplicated IDs)
# Print the total count of duplicated IDs
print(duplicate_ids_count_vald)
# Group by TOTAL_NB_VALD, ID_REFA_LDA, and JOUR, and count duplicates
grouped_duplicates <- result %>%
group_by(TOTAL_NB_VALD, ID_REFA_LDA, JOUR) %>%
summarize(Count = n(), .groups = 'drop') %>%  # Count the occurrences for each group
filter(Count > 1)  # Keep only groups with duplicates
# Group by TOTAL_NB_VALD, ID_REFA_LDA, and JOUR, and count duplicates
grouped_duplicates <- result %>%
group_by(Total_NB_VALD, ID_REFA_LDA, JOUR) %>%
summarize(Count = n(), .groups = 'drop') %>%  # Count the occurrences for each group
filter(Count > 1)  # Keep only groups with duplicates
# Print the grouped duplicates
print(grouped_duplicates)
# Count the total number of duplicates
total_duplicates <- nrow(grouped_duplicates)
print(total_duplicates)
# Group by TOTAL_NB_VALD, ID_REFA_LDA, and JOUR, and count duplicates
grouped_duplicates <- result %>%
group_by(Total_NB_VALD, ID_REFA_LDA) %>%
summarize(Count = n(), .groups = 'drop') %>%  # Count the occurrences for each group
filter(Count > 1)  # Keep only groups with duplicates
# Print the grouped duplicates
print(grouped_duplicates)
# Count the total number of duplicates
total_duplicates <- nrow(grouped_duplicates)
print(total_duplicates)
#subset_data <- result$Total_NB_VALD[1:(6 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(result$Total_NB_VALD, frequency = 7))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(6 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 30))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(72 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 30))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(72 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 365))
# Plot the decomposed time series
plot(decomposition)
subset_data <- result$Total_NB_VALD[1:(12 * 30)]
# Set frequency to 7 for weekly seasonality (adjust as needed)
decomposition <- decompose(ts(subset_data, frequency = 30))
# Plot the decomposed time series
plot(decomposition)
subset_data_2 <- result$Total_NB_VALD[1:(2 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition2 <- decompose(ts(subset_data_2, frequency = 7))
# Plot the decomposed time series
plot(decomposition2)
subset_data_3 <- result$Total_NB_VALD[1:(24 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_2, frequency = 364))
subset_data_3 <- result$Total_NB_VALD[1:(24 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
subset_data_3 <- result$Total_NB_VALD[1:(26 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- result$Total_NB_VALD[1:(36 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- result$Total_NB_VALD[1:(39 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- result$Total_NB_VALD[1:(50 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- result$Total_NB_VALD[1:(72 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- result$Total_NB_VALD[1:(25 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- monthly_data$Total_NB_VALD[1:(25 * 30)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 364))
subset_data_3 <- monthly_data$Total_NB_VALD[1:(48 * 12)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 12))
# Plot the decomposed time series
plot(decomposition3)
subset_data_3 <- monthly_data$Total_NB_VALD[1:(48 * 12)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 1))
subset_data_3 <- monthly_data$Total_NB_VALD[1:(4 * 12)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(subset_data_3, frequency = 1))
monthly_data
#subset_data_3 <- monthly_data$Total_NB_VALD[1:(4 * 12)]
# Set frequency to 7 for weekely seasonality (adjust as needed)
decomposition3 <- decompose(ts(monthly_data$Total_NB_VALD, frequency = 1))
#subset_data_3 <- monthly_data$Total_NB_VALD[1:(4 * 12)]
decomposition3 <- decompose(ts(monthly_data$Total_NB_VALD, start = c(2018, 1), frequency = 12))
plot(decomposition3)
#subset_data_3 <- monthly_data$Total_NB_VALD[1:(4 * 12)]
decomposition3 <- decompose(ts(monthly_data$Total_NB_VALD, start = c(2018, 1), frequency = 1))
#subset_data_3 <- monthly_data$Total_NB_VALD[1:(4 * 12)]
decomposition3 <- decompose(ts(monthly_data$Total_NB_VALD, start = c(2018, 1), frequency = 12))
plot(decomposition3)
monthly_data
library(dplyr)
library(sf)
library(leaflet)
# Filter data based on IDs
filtered_new_data <- filtered_data %>%
filter(ZdCId %in% result$ID_REFA_LDA)
# Convert to spatial object
final_data_sf <- st_as_sf(filtered_new_data, coords = c("ZdAXEpsg2154", "ZdAYEpsg2154"), crs = 2154)
# Transform to EPSG 4326
final_data_sf <- st_transform(final_data_sf, 4326)
# Extract coordinates
filtered_new_data$X <- st_coordinates(final_data_sf)[, "X"]
filtered_new_data$Y <- st_coordinates(final_data_sf)[, "Y"]
# Create leaflet map
my_map <- leaflet() %>%
addTiles() %>%
setView(
lng = mean(st_coordinates(final_data_sf$geometry)[, "X"]),
lat = mean(st_coordinates(final_data_sf$geometry)[, "Y"]),
zoom = 11
) %>%
addMarkers(
data = filtered_new_data,
lng = ~X,  # Use the X column for longitude
lat = ~Y   # Use the Y column for latitude
)
# Show the map
my_map
library(lubridate)
library(lubridate)
result$Weekday <- weekdays(result$JOUR)
# Identify holiday periods
holidays <- as.Date(c("2017-12-25", "2018-01-01", "2018-07-14", "2018-12-25", "2019-01-01", "2019-07-14", "2019-12-25", "2020-01-01", "2020-07-14", "2020-12-25", "2021-01-01", "2021-07-14", "2021-12-25", "2022-01-01", "2022-07-14"))
# Create a variable indicating holiday or non-holiday
result$HolidayType <- ifelse(floor_date(result$JOUR, "day") %in% holidays, "Holiday", "Non-Holiday")
# Group by weekday and calculate the mean for each day of the week
mean_by_weekday <- result %>%
group_by(Weekday, HolidayType) %>%
summarize(Mean_Sum_NB_VALD = mean(Total_NB_VALD, na.rm = TRUE))
# Calculate the mean for holiday days
mean_holiday <- mean_by_weekday %>%
filter(HolidayType == "Holiday") %>%
summarize(Mean_Sum_NB_VALD_Holiday = mean(Mean_Sum_NB_VALD, na.rm = TRUE))
ggplot(mean_by_weekday, aes(x = Weekday, y = Mean_Sum_NB_VALD, color = HolidayType)) +
geom_point(size = 3) +
#geom_point(data = mean_holiday, aes(x = "Holiday", y = Mean_Sum_NB_VALD_Holiday), size = 3, color = "red") +
labs(title = "Mean Sum_NB_VALD Comparison",
x = "Day of the Week",
y = "Mean Sum_NB_VALD",
color = "Period") +
theme_minimal()
# Function to check if a date is within a special period
is_special_period <- function(date, special_periods) {
return(any(date %in% special_periods))
}
# Get the range of years in your dataset
data_years <- unique(year(final_data$JOUR))
# Function to check if a date is within a special period
is_special_period <- function(date, special_periods) {
return(any(date %in% special_periods))
}
# Get the range of years in your dataset
data_years <- unique(year(result$JOUR))
# Initialize an empty vector to store special periods
special_periods <- c()
# Loop through each year and add sequences to the special_periods vector
for (year_val in data_years) {
start_date1 <- as.Date(sprintf("%d-12-17", year_val))
end_date1 <- as.Date(sprintf("%d-01-03", year_val + 1))
start_date2 <- as.Date(sprintf("%d-02-04", year_val))
end_date2 <- as.Date(sprintf("%d-02-20", year_val))
special_periods <- c(special_periods, seq(start_date1, end_date1, by = "days"), seq(start_date2, end_date2, by = "days"))
}
# Convert numerical representations to dates
special_periods <- as.Date(special_periods, origin="1970-01-01")
print(special_periods)
result$SpecialPeriod <- as.integer(result$JOUR %in% special_periods)
# Group by weekday and special period, calculate the mean for each day
mean_by_weekday_and_special_period <- result %>%
group_by(Weekday, SpecialPeriod) %>%
summarize(Mean_Sum_NB_VALD = mean(Total_NB_VALD, na.rm = TRUE))
# Plot the comparison
ggplot(mean_by_weekday_and_special_period, aes(x = Weekday, y = Mean_Sum_NB_VALD, color = SpecialPeriod)) +
geom_point(size = 3) +
labs(title = "Mean Sum_NB_VALD Comparison",
x = "Day of the Week",
y = "Mean Sum_NB_VALD",
color = "Special Period") +
theme_minimal()
